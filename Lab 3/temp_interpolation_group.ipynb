{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from arcpy import sa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create database connection - only do this step if connection in arcgis pro not already established\n",
    "arcpy.management.CreateDatabaseConnection(\n",
    "    out_folder_path=r\"C:\\Users\\KOlso\\Documents\\GIS5572\",\n",
    "    out_name=\"Test\",\n",
    "    database_platform=\"POSTGRESQL\",\n",
    "    instance=\"34.30.71.239\",\n",
    "    account_authentication=\"DATABASE_AUTH\",\n",
    "    username=\"postgres\",\n",
    "    password='',\n",
    "    save_user_pass=\"SAVE_USERNAME\",\n",
    "    database=\"gis_data\",\n",
    "    schema=\"\",\n",
    "    version_type=\"TRANSACTIONAL\",\n",
    "    version=\"\",\n",
    "    date=None,\n",
    "    auth_type=\"\",\n",
    "    project_id=\"\",\n",
    "    default_dataset=\"\",\n",
    "    refresh_token='',\n",
    "    key_file=None,\n",
    "    role=\"\",\n",
    "    warehouse=\"\",\n",
    "    advanced_options=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to databse - retrieve temperature data for Aug 31, 2024 - convert to fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature class created from psycopg2 data.\n"
     ]
    }
   ],
   "source": [
    "#connect to db and grab the columns we want to use, turn this into a fc we'll use as basis for interpolations.\n",
    "#In this case we are using August 31st data but could in theory pick any day from August since that is what we have in db\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"gis_data\",\n",
    "    user=\"\",\n",
    "    password=\"\",\n",
    "    host=\"34.30.71.239\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    SELECT stid, \"20240831\", name, ST_AsText(geometry) \n",
    "    FROM gis_data.public.mesonet\n",
    "\"\"\")\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "\n",
    "#Prepare new feature class - \"alt\" is used here because I considered another method I abandoned and I didn't want to change all the variables\n",
    "output_fc = r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\\mesonet_fc_alt\"\n",
    "sr = arcpy.SpatialReference(4326)  # Adjust if your data uses a different SRID\n",
    "\n",
    "# Create the feature class\n",
    "arcpy.management.CreateFeatureclass(\n",
    "    out_path=r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\",\n",
    "    out_name=\"mesonet_fc_alt\",\n",
    "    geometry_type=\"POINT\",\n",
    "    spatial_reference=sr\n",
    ")\n",
    "\n",
    "# Add fields to the feature class\n",
    "arcpy.management.AddField(output_fc, \"stid\", \"TEXT\", field_length=50)\n",
    "arcpy.management.AddField(output_fc, \"temp_20240831\", \"DOUBLE\")\n",
    "arcpy.management.AddField(output_fc, \"name\", \"TEXT\", field_length=100)\n",
    "\n",
    "# Insert features from the db table\n",
    "with arcpy.da.InsertCursor(output_fc, [\"stid\", \"temp_20240831\", \"name\", \"SHAPE@XY\"]) as cursor:\n",
    "    for stid, temp, name, geom_wkt in rows:\n",
    "        try:\n",
    "            # Convert WKT to geometry using arcpy\n",
    "            geom = arcpy.FromWKT(geom_wkt)  # Convert WKT to geometry\n",
    "            cursor.insertRow((stid, temp, name, (geom.centroid.X, geom.centroid.Y)))  # Use centroid for point\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing WKT for {stid}: {e}\")\n",
    "\n",
    "print(\"Feature class created from psycopg2 data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate with all points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inerpolation 1 IDW\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\"):\n",
    "    out_raster = arcpy.sa.Idw(\n",
    "        in_point_features=\"mesonet_fc_alt\",\n",
    "        z_field=\"temp_20240831\",\n",
    "        cell_size=0.0005,\n",
    "        power=2,\n",
    "        search_radius=\"VARIABLE 12\",\n",
    "        in_barrier_polyline_features=None\n",
    "    )\n",
    "    out_raster.save(r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\\mesonet_alt_IDW_all\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolation 2 - Ordinary Kriging from spatial analyst toolbox\n",
    "\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\"):\n",
    "    out_surface_raster = arcpy.sa.Kriging(\n",
    "        in_point_features=\"mesonet_fc_alt\",\n",
    "        z_field=\"temp_20240831\",\n",
    "        kriging_model=\"Spherical # # # #\",\n",
    "        cell_size=0.0005,\n",
    "        search_radius=\"VARIABLE 12\",\n",
    "        out_variance_prediction_raster=None\n",
    "    )\n",
    "    out_surface_raster.save(r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\\mesonet_alt_okri_all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolation #3 - Universal Kriging from spatial analyst toolbox\n",
    "\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\"):\n",
    "    out_surface_raster = arcpy.sa.Kriging(\n",
    "        in_point_features=\"mesonet_fc_alt\",\n",
    "        z_field=\"temp_20240831\",\n",
    "        kriging_model=\"LinearDrift 0.000500 # # #\",\n",
    "        cell_size=0.0005,\n",
    "        search_radius=\"VARIABLE 12\",\n",
    "        out_variance_prediction_raster=None\n",
    "    )\n",
    "    out_surface_raster.save(r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\\mesonet_alt_ukri_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Thursday, April 10, 2025 11:16:20 AM<br>Calculating Ordinary Kriging – Default<br>\\r\\nWarning(s) for dataset: mesonet_fc_alt<br>WARNING 040402: NODATA value ignored. ObjectID = 7<br>Calculating Ordinary Kriging – Optimized<br>\\r\\nWarning(s) for dataset: mesonet_fc_alt<br>WARNING 040402: NODATA value ignored. ObjectID = 7<br>Calculating Universal Kriging – Default<br>\\r\\nWarning(s) for dataset: mesonet_fc_alt<br>WARNING 040402: NODATA value ignored. ObjectID = 7<br>Calculating Universal Kriging – Optimized<br>\\r\\nWarning(s) for dataset: mesonet_fc_alt<br>WARNING 040402: NODATA value ignored. ObjectID = 7<br>Calculating Inverse Distance Weighted - Default<br>\\r\\nWarning(s) for dataset: mesonet_fc_alt<br>WARNING 040402: NODATA value ignored. ObjectID = 7<br>Calculating Inverse Distance Weighted - Optimized<br>\\r\\nWarning(s) for dataset: mesonet_fc_alt<br>WARNING 040402: NODATA value ignored. ObjectID = 7<br>\\r\\nWarning(s) for dataset: mesonet_fc_alt<br>WARNING 040402: NODATA value ignored. ObjectID = 7<br> \\n<br>--------------------------------------------<br>RANK | NAME<br>--------------------------------------------<br>\\n<br>1    | Ordinary Kriging – Optimized<br>\\n<br>2    | Inverse Distance Weighted - Optimized<br>\\n<br>3    | Ordinary Kriging – Default<br>\\n<br>4    | Universal Kriging – Optimized<br>\\n<br>5    | Inverse Distance Weighted - Default<br>\\n<br>6    | Universal Kriging – Default<br>--------------------------------------------<br>Succeeded at Thursday, April 10, 2025 11:16:32 AM (Elapsed Time: 12.54 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'G:\\\\ArcGIS\\\\Projects\\\\5572\\\\5572.gdb\\\\Temp_0831_ExpInt_table'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy assessment - one approach similar to what Nicole did for Elevation but I wanted to do it differently but this is still here\n",
    "# arcpy.ga.ExploratoryInterpolation(\n",
    "#     in_features=\"mesonet_fc_alt\",\n",
    "#     value_field=\"temp_20240831\",\n",
    "#     out_cv_table=r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\\Temp_0831_ExpInt_table\",\n",
    "#     out_geostat_layer=\"test_output_ex_int\",\n",
    "#     interp_methods=\"ORDINARY_KRIGING;UNIVERSAL_KRIGING;IDW\",\n",
    "#     comparison_method=\"SINGLE\",\n",
    "#     criterion=\"ACCURACY\",\n",
    "#     criteria_hierarchy=\"ACCURACY PERCENT #\",\n",
    "#     weighted_criteria=\"ACCURACY 1\",\n",
    "#     exclusion_criteria=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results - Using K-folds cross validation - 3 points per fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment - probably not necessary since I'm already working here\n",
    "arcpy.env.workspace = r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Inputs used for all three cross validations we'll perform. Cell size is partially arbitrary but at this latitude is roughly 50 square meters\n",
    "input_fc = \"mesonet_fc_alt\"\n",
    "z_field = \"temp_20240831\"\n",
    "id_field = \"stid\"\n",
    "cell_size = .0005  # Adjustable but should be in this scale since data is all 4326 so unit is decimal degrees\n",
    "num_folds = 9\n",
    "fold_size = 3\n",
    "output_table_base = \"cv_results\"  # Base name for all output tables\n",
    "\n",
    "# Set extent to match the feature class - this is necessary so extent is same for all folds (otherwise edge points may get left out sometimes)\n",
    "extent = arcpy.Describe(input_fc).extent\n",
    "arcpy.env.extent = extent\n",
    "\n",
    "# Create list of all OIDs and assign to folds - these are the folds used in the k-folds analysis that will be used for each cross validation\n",
    "oids = [row[0] for row in arcpy.da.SearchCursor(input_fc, [\"OID@\"])]\n",
    "random.shuffle(oids)\n",
    "folds = [oids[i:i+fold_size] for i in range(0, len(oids), fold_size)]\n",
    "\n",
    "# Create a function that will create a table for each cross validation of an interpolation method\n",
    "def create_validation_table(output_table_name):\n",
    "    \"\"\"Creates a validation table with MAE and difference columns\"\"\"\n",
    "    if arcpy.Exists(output_table_name):\n",
    "        arcpy.management.Delete(output_table_name)\n",
    "    arcpy.management.CreateTable(arcpy.env.workspace, output_table_name)\n",
    "    arcpy.management.AddField(output_table_name, \"Fold\", \"SHORT\")\n",
    "    arcpy.management.AddField(output_table_name, \"OID\", \"LONG\")\n",
    "    arcpy.management.AddField(output_table_name, \"stid\", \"TEXT\", field_length=50)\n",
    "    arcpy.management.AddField(output_table_name, \"Actual\", \"DOUBLE\")\n",
    "    arcpy.management.AddField(output_table_name, \"Predicted\", \"DOUBLE\")\n",
    "    arcpy.management.AddField(output_table_name, \"Difference\", \"DOUBLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDW cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1...\n",
      "Processing fold 2...\n",
      "Processing fold 3...\n",
      "Processing fold 4...\n",
      "Processing fold 5...\n",
      "Processing fold 6...\n",
      "Processing fold 7...\n",
      "Processing fold 8...\n",
      "Processing fold 9...\n",
      "✅ Cross-validation with IDW complete. Results saved to 'idw_cv_results'.\n"
     ]
    }
   ],
   "source": [
    "# Set the output table name for IDW results\n",
    "output_table_idw = f\"{output_table_base}_IDW\"\n",
    "\n",
    "# Create a table to store results for IDW\n",
    "create_validation_table(output_table_idw)\n",
    "\n",
    "# Perform IDW cross-validation\n",
    "for i, test_oids in enumerate(folds):\n",
    "    print(f\"Processing fold {i+1}...\")\n",
    "\n",
    "    # Create training and testing feature layers\n",
    "    train_layer = f\"train_{i}\"\n",
    "    test_layer = f\"test_{i}\"\n",
    "    test_oid_str = \",\".join(str(oid) for oid in test_oids)\n",
    "    train_where = f\"OBJECTID NOT IN ({test_oid_str})\"\n",
    "    test_where = f\"OBJECTID IN ({test_oid_str})\"\n",
    "\n",
    "    arcpy.management.MakeFeatureLayer(input_fc, train_layer, train_where)\n",
    "    arcpy.management.MakeFeatureLayer(input_fc, test_layer, test_where)\n",
    "\n",
    "    # Run IDW interpolation\n",
    "    idw_raster = arcpy.sa.Idw(\n",
    "        in_point_features=train_layer,\n",
    "        z_field=z_field,\n",
    "        cell_size=cell_size\n",
    "    )\n",
    "\n",
    "    idw_raster_name = f\"idw_fold_{i+1}\"\n",
    "    idw_raster.save(idw_raster_name)\n",
    "\n",
    "    # Extract predicted values to test points \n",
    "    test_with_prediction = f\"test_with_pred_{i}\"\n",
    "    arcpy.sa.ExtractValuesToPoints(test_layer, idw_raster, test_with_prediction, interpolate_values=\"NONE\")\n",
    "\n",
    "    # Record actual vs predicted temperatures at each point\n",
    "    fields = [\"Fold\", \"OID@\", id_field, z_field, \"RASTERVALU\"]\n",
    "    with arcpy.da.SearchCursor(test_with_prediction, [\"OID@\", id_field, z_field, \"RASTERVALU\"]) as cursor_in, \\\n",
    "         arcpy.da.InsertCursor(output_table_idw, [\"Fold\", \"OID\", \"stid\", \"Actual\", \"Predicted\", \"Difference\"]) as cursor_out:\n",
    "        for row in cursor_in:\n",
    "            actual_value = row[2]\n",
    "            predicted_value = row[3]\n",
    "            \n",
    "            # Check if both actual and predicted values are not None\n",
    "            if actual_value is not None and predicted_value is not None:\n",
    "                diff = predicted_value - actual_value  # Difference = Predicted - Actual\n",
    "                cursor_out.insertRow((i + 1, row[0], row[1], actual_value, predicted_value, diff))\n",
    "            else:\n",
    "                # If either value is None, you can handle it by skipping or inserting a null value\n",
    "                cursor_out.insertRow((i + 1, row[0], row[1], actual_value, predicted_value, None))\n",
    "\n",
    "\n",
    "    # Clean up\n",
    "    arcpy.management.Delete(train_layer)\n",
    "    arcpy.management.Delete(test_layer)\n",
    "    arcpy.management.Delete(test_with_prediction)\n",
    "    arcpy.management.Delete(idw_raster)\n",
    "\n",
    "print(\"Cross-validation with IDW complete. Results saved to 'cv_results_idw'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Kriging Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1...\n",
      "Processing fold 2...\n",
      "Processing fold 3...\n",
      "Processing fold 4...\n",
      "Processing fold 5...\n",
      "Processing fold 6...\n",
      "Processing fold 7...\n",
      "Processing fold 8...\n",
      "Processing fold 9...\n",
      "Cross-validation with Ordinary Kriging complete. Results saved to 'cv_results_OK'.\n"
     ]
    }
   ],
   "source": [
    "# Set the output table name for OK results\n",
    "output_table_ok = f\"{output_table_base}_OK\"\n",
    "\n",
    "# Create a table to store results for Ordinary Kriging\n",
    "create_validation_table(output_table_ok)\n",
    "\n",
    "# Perform Ordinary Kriging cross-validation\n",
    "for i, test_oids in enumerate(folds):\n",
    "    print(f\"Processing fold {i+1}...\")\n",
    "\n",
    "    # Create training and testing feature layers\n",
    "    train_layer = f\"train_{i}\"\n",
    "    test_layer = f\"test_{i}\"\n",
    "    test_oid_str = \",\".join(str(oid) for oid in test_oids)\n",
    "    train_where = f\"OBJECTID NOT IN ({test_oid_str})\"\n",
    "    test_where = f\"OBJECTID IN ({test_oid_str})\"\n",
    "\n",
    "    arcpy.management.MakeFeatureLayer(input_fc, train_layer, train_where)\n",
    "    arcpy.management.MakeFeatureLayer(input_fc, test_layer, test_where)\n",
    "\n",
    "    # Run Ordinary Kriging interpolation\n",
    "    ok_result = arcpy.sa.Kriging(\n",
    "        in_point_features=train_layer,\n",
    "        z_field=z_field,\n",
    "        kriging_model=\"Spherical\",  # Change as needed\n",
    "        cell_size=cell_size,\n",
    "        search_radius=\"VARIABLE 12\"\n",
    "    )\n",
    "\n",
    "    ok_raster_name = f\"ok_fold_{i+1}\"\n",
    "    ok_result.save(ok_raster_name)\n",
    "\n",
    "    # Extract predicted values to test points\n",
    "    test_with_prediction = f\"test_with_pred_{i}\"\n",
    "    arcpy.sa.ExtractValuesToPoints(test_layer, ok_result, test_with_prediction, interpolate_values=\"NONE\")\n",
    "\n",
    "    # Record actual vs predicted temperatures at each point\n",
    "    fields = [\"Fold\", \"OID@\", id_field, z_field, \"RASTERVALU\"]\n",
    "    with arcpy.da.SearchCursor(test_with_prediction, [\"OID@\", id_field, z_field, \"RASTERVALU\"]) as cursor_in, \\\n",
    "         arcpy.da.InsertCursor(output_table_ok, [\"Fold\", \"OID\", \"stid\", \"Actual\", \"Predicted\", \"Difference\"]) as cursor_out:\n",
    "        for row in cursor_in:\n",
    "            actual_value = row[2]\n",
    "            predicted_value = row[3]\n",
    "            \n",
    "            # Check if both actual and predicted values are not None\n",
    "            if actual_value is not None and predicted_value is not None:\n",
    "                diff = predicted_value - actual_value  # Difference = Predicted - Actual\n",
    "                cursor_out.insertRow((i + 1, row[0], row[1], actual_value, predicted_value, diff))\n",
    "            else:\n",
    "                # If either value is None, you can handle it by skipping or inserting a null value\n",
    "                cursor_out.insertRow((i + 1, row[0], row[1], actual_value, predicted_value, None))\n",
    "\n",
    "    # Clean up\n",
    "    arcpy.management.Delete(train_layer)\n",
    "    arcpy.management.Delete(test_layer)\n",
    "    arcpy.management.Delete(test_with_prediction)\n",
    "    arcpy.management.Delete(ok_result)\n",
    "\n",
    "print(\"Cross-validation with Ordinary Kriging complete. Results saved to 'cv_results_OK'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Kriging Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1...\n",
      "Processing fold 2...\n",
      "Processing fold 3...\n",
      "Processing fold 4...\n",
      "Processing fold 5...\n",
      "Processing fold 6...\n",
      "Processing fold 7...\n",
      "Processing fold 8...\n",
      "Processing fold 9...\n",
      "Cross-validation with Universal Kriging complete. Results saved to 'cv_results_UK'.\n"
     ]
    }
   ],
   "source": [
    "# Set the output table name for UK results\n",
    "output_table_uk = f\"{output_table_base}_UK\"\n",
    "\n",
    "# Create a table to store results for Universal Kriging\n",
    "create_validation_table(output_table_uk)\n",
    "\n",
    "# Perform Universal Kriging cross-validation\n",
    "for i, test_oids in enumerate(folds):\n",
    "    print(f\"Processing fold {i+1}...\")\n",
    "\n",
    "    # Create training and testing feature layers\n",
    "    train_layer = f\"train_{i}\"\n",
    "    test_layer = f\"test_{i}\"\n",
    "    test_oid_str = \",\".join(str(oid) for oid in test_oids)\n",
    "    train_where = f\"OBJECTID NOT IN ({test_oid_str})\"\n",
    "    test_where = f\"OBJECTID IN ({test_oid_str})\"\n",
    "\n",
    "    arcpy.management.MakeFeatureLayer(input_fc, train_layer, train_where)\n",
    "    arcpy.management.MakeFeatureLayer(input_fc, test_layer, test_where)\n",
    "\n",
    "    # Record actual vs predicted temperatures at each point\n",
    "    uk_result = arcpy.sa.Kriging(\n",
    "        in_point_features=train_layer,\n",
    "        z_field=z_field,\n",
    "        kriging_model=\"LinearDrift 0.000500 # # #\",\n",
    "        cell_size=cell_size,\n",
    "        search_radius=\"VARIABLE 12\",\n",
    "    )\n",
    "\n",
    "    uk_raster_name = f\"uk_fold_{i+1}\"\n",
    "    uk_result.save(uk_raster_name)\n",
    "\n",
    "    # Extract predicted values to test points\n",
    "    test_with_prediction = f\"test_with_pred_{i}\"\n",
    "    arcpy.sa.ExtractValuesToPoints(test_layer, uk_result, test_with_prediction, interpolate_values=\"NONE\")\n",
    "\n",
    "    # Record actual vs predicted\n",
    "    fields = [\"Fold\", \"OID@\", id_field, z_field, \"RASTERVALU\"]\n",
    "    with arcpy.da.SearchCursor(test_with_prediction, [\"OID@\", id_field, z_field, \"RASTERVALU\"]) as cursor_in, \\\n",
    "         arcpy.da.InsertCursor(output_table_uk, [\"Fold\", \"OID\", \"stid\", \"Actual\", \"Predicted\", \"Difference\"]) as cursor_out:\n",
    "        for row in cursor_in:\n",
    "            actual_value = row[2]\n",
    "            predicted_value = row[3]\n",
    "            \n",
    "            # Check if both actual and predicted values are not None\n",
    "            if actual_value is not None and predicted_value is not None:\n",
    "                diff = predicted_value - actual_value  # Difference = Predicted - Actual\n",
    "                cursor_out.insertRow((i + 1, row[0], row[1], actual_value, predicted_value, diff))\n",
    "            else:\n",
    "                # If either value is None, you can handle it by skipping or inserting a null value\n",
    "                cursor_out.insertRow((i + 1, row[0], row[1], actual_value, predicted_value, None))\n",
    "    # Clean up\n",
    "    arcpy.management.Delete(train_layer)\n",
    "    arcpy.management.Delete(test_layer)\n",
    "    arcpy.management.Delete(test_with_prediction)\n",
    "    arcpy.management.Delete(ok_result)\n",
    "   \n",
    "print(\"Cross-validation with Universal Kriging complete. Results saved to 'cv_results_UK'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE and MAE for each interpolation Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Method    MAE   RMSE\n",
      "0               IDW  0.431  0.564\n",
      "1   OrdinaryKriging  0.510  0.589\n",
      "2  UniversalKriging  0.469  0.655\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary for the table names that we'll use for calulating our evaluation metrics\n",
    "table_paths = {\n",
    "    \"IDW\": \"cv_results_IDW\",\n",
    "    \"OrdinaryKriging\": \"cv_results_OK\",\n",
    "    \"UniversalKriging\": \"cv_results_UK\"\n",
    "}\n",
    "\n",
    "# create list for results to sit in\n",
    "results = []\n",
    "\n",
    "for method, table in table_paths.items():\n",
    "    # Load into pandas\n",
    "    arr = arcpy.da.TableToNumPyArray(table, [\"Actual\", \"Predicted\"])\n",
    "    df = pd.DataFrame(arr)\n",
    "\n",
    "    # Drop nulls\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Extract values\n",
    "    y_true = df[\"Actual\"].to_numpy()\n",
    "    y_pred = df[\"Predicted\"].to_numpy()\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = np.mean(np.abs(y_pred - y_true))\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "    results.append({\n",
    "        \"Method\": method,\n",
    "        \"MAE\": round(mae, 3),\n",
    "        \"RMSE\": round(rmse, 3)\n",
    "    })\n",
    "\n",
    "# Create and display results table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert best interpolation to points, join table with differences to a feature class for upload to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Friday, April 11, 2025 5:40:10 PM<br>Succeeded at Friday, April 11, 2025 5:40:20 PM (Elapsed Time: 9.83 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'G:\\\\ArcGIS\\\\Projects\\\\5572\\\\5572.gdb\\\\Mesonet_IDW_RtP'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looks like IDW has the smallest MAE and RMSE - we're only ever off by about half a degree or less. \n",
    "\n",
    "#Now we convert our IDW Raster from earlier to point for easier display in the webmap via database connection\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=\"Mesonet_alt_IDW\",\n",
    "    out_point_features=r\"G:\\ArcGIS\\Projects\\5572\\5572.gdb\\Mesonet_IDW_RtP\",\n",
    "    raster_field=\"Value\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields added and populated successfully.\n"
     ]
    }
   ],
   "source": [
    "#set variables to join tables so we can have  both actual and predicted results\n",
    "\n",
    "source_table = \"cv_results_IDW\"\n",
    "target_fc = \"mesonet_fc_alt\"\n",
    "join_field = \"stid\"\n",
    "fields_to_add = [\"Predicted\", \"Difference\"]\n",
    "\n",
    "# Create dictionary to store data from cv_results_IDW table\n",
    "value_dict = {}\n",
    "with arcpy.da.SearchCursor(source_table, [join_field] + fields_to_add) as cursor:\n",
    "    for row in cursor:\n",
    "        value_dict[row[0]] = row[1:]  # key: stid, value: (Predicted, Difference)\n",
    "\n",
    "#Add new fields to my feature class\n",
    "arcpy.management.AddField(target_fc, \"IDW_Predicted\", \"DOUBLE\")\n",
    "arcpy.management.AddField(target_fc, \"Difference\", \"DOUBLE\")\n",
    "\n",
    "#Update feature class with values from dictionary, joining on stid field\n",
    "with arcpy.da.UpdateCursor(target_fc, [join_field, \"IDW_Predicted\", \"Difference\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        stid = row[0]\n",
    "        if stid in value_dict:\n",
    "            row[1], row[2] = value_dict[stid]\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "print(\"Fields added and populated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload interpolatation layer and feature class with differences to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we'll do the newly updated feature class with the difference column (requirement 2F from lab instructions)\n",
    "\n",
    "# set feature class variable\n",
    "fc1 = \"mesonet_fc_alt\"\n",
    "\n",
    "# Connect to PostGIS\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"gis_data\",\n",
    "    user=\"\",\n",
    "    password=\"\",\n",
    "    host=\"34.30.71.239\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Drop and recreate table\n",
    "cur.execute(\"DROP TABLE IF EXISTS temp_station_points;\")\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE temp_station_points (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        stid TEXT,\n",
    "        temp_20240831 DOUBLE PRECISION,\n",
    "        name TEXT,\n",
    "        idw_predicted DOUBLE PRECISION,\n",
    "        difference DOUBLE PRECISION,\n",
    "        geom GEOMETRY(POINT, 4326)\n",
    "    );\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# Insert rows from feature class\n",
    "with arcpy.da.SearchCursor(fc1, [\"SHAPE@XY\", \"stid\", \"temp_20240831\", \"name\", \"IDW_Predicted\", \"Difference\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        (x, y) = row[0]\n",
    "        stid = row[1]\n",
    "        temp = row[2]\n",
    "        name = row[3]\n",
    "        predicted = row[4]\n",
    "        difference = row[5]\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO temp_station_points (stid, temp_20240831, name, idw_predicted, difference, geom)\n",
    "            VALUES (%s, %s, %s, %s, %s, ST_SetSRID(ST_Point(%s, %s), 4326));\n",
    "        \"\"\", (stid, temp, name, predicted, difference, x, y))\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Temperature points uploaded to db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we'll push the points converted from the raster\n",
    "\n",
    "# set feature class variable\n",
    "fc2 = \"Mesonet_IDW_RtP\"\n",
    "\n",
    "# Connect to PostGIS\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"gis_data\",\n",
    "    user=\"\",\n",
    "    password=\"\",\n",
    "    host=\"34.30.71.239\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Recreate the table\n",
    "cur.execute(\"DROP TABLE IF EXISTS temp_raster_points_IDW;\")\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE temp_raster_points_IDW (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        pointid INTEGER,\n",
    "        grid_code DOUBLE PRECISION,\n",
    "        geom GEOMETRY(POINT, 4326)\n",
    "    );\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# Insert rows from the feature class\n",
    "with arcpy.da.SearchCursor(fc2, [\"SHAPE@XY\", \"pointid\", \"grid_code\"]) as cursor:\n",
    "    for (shape_xy, pointid, grid_code) in cursor:\n",
    "        x, y = shape_xy\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO temp_raster_points_IDW (pointid, grid_code, geom)\n",
    "            VALUES (%s, %s, ST_SetSRID(ST_Point(%s, %s), 4326));\n",
    "        \"\"\", (pointid, grid_code, x, y))\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Temperature raster ponts uploaded to db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accucary assessment table uploaded to db\n"
     ]
    }
   ],
   "source": [
    "#lastly, we'll send the accuracy assessment table from ealier\n",
    "\n",
    "#This one is just a dataframe, not a feature class, so a slightly different approach is needed.\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "# Connection setup\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"gis_data\",\n",
    "    user=\"\",\n",
    "    password=\"\",\n",
    "    host=\"34.30.71.239\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create table\n",
    "cur.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS interpolation_stats;\n",
    "    CREATE TABLE interpolation_stats (\n",
    "        method TEXT,\n",
    "        mae DOUBLE PRECISION,\n",
    "        rmse DOUBLE PRECISION\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Insert rows\n",
    "for _, row in results_df.iterrows():\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO interpolation_stats (method, mae, rmse)\n",
    "        VALUES (%s, %s, %s);\n",
    "    \"\"\", (row[\"Method\"], row[\"MAE\"], row[\"RMSE\"]))\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Accucary assessment table uploaded to db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
